# YouTube App - Production System Log

## Core Instructions for Coding Agents

You are a coding agent working with a production-ready YouTube scraper system.
You have 2 rules:
**1. No tech debt** - If a problem arises, we provide the long-term solution right away.
**2. No data fabrication** - Errors always preferred over mock data or fallback placeholders.

## Project Overview

- **Project Name**: youtube_app (Alpine-based wget collection)
- **Database**: Firebase Firestore (credentials via file path in .env)
- **Caching**: Upstash Redis with REST API client
- **Runtime**: Python 3.10+ on Alpine Linux VM
- **Deployment**: GitHub Actions auto-deployment on push to main
- **VM**: SSH to VM using `/workspace/droplet1` (private key) - IP: 134.199.201.56
- **Location**: `/opt/youtube_app` on VM
- **Repository**: https://github.com/canaanhowell/youtube-scraper-production

## Current Status (2025-08-06)

### ðŸš€ **Multi-Instance Collection System Active**

The YouTube scraper is running with a new multi-instance architecture to handle scaling:

âœ… **System Status**:
- **VM**: Running at 134.199.201.56 - 4 vCPU, 8GB RAM
- **Project Path**: `/opt/youtube_app/`
- **VPN System**: 3 VPN containers (youtube-vpn-1, youtube-vpn-2, youtube-vpn-3) with staggered access
- **Collection**: 3 instances processing keywords in parallel
- **Firebase**: Connected with proper logging format
- **Redis**: Upstash Redis REST API configured
- **Deployment**: GitHub Actions auto-deployment ACTIVE
- **Analytics Pipeline**: Fully operational with interval and daily metrics
- **Collection Method**: wget-based (20 videos per keyword)
- **Collection Schedule**: Every 10 minutes via cron (staggered multi-instance)

### ðŸ”§ **Latest Updates (2025-08-06)**:

**ðŸŽ¯ Exact Phrase Matching Implementation - DEPLOYED** (Evening):
- âœ… **Enhanced Keyword Filtering**: Implemented exact phrase matching for multi-word keywords
- âœ… **Issue Addressed**: Previous fuzzy matching allowed words in wrong order (e.g., "AI Character" matching "character ai")
- âœ… **Solution**: Updated `_title_contains_keyword()` to require exact phrase matches with proper spacing
- âœ… **Examples**: "character ai" must appear as "Character AI" or "character-ai" (hyphenated variant supported)
- âœ… **Impact**: Eliminates false matches where keyword words appear separately or in wrong order
- âœ… **Configuration**: YOUTUBE_STRICT_TITLE_FILTER=true enabled for exact phrase filtering
- âœ… **Code Updated**: Both wget and Playwright filtering methods use consistent exact matching logic
- âœ… **Deployed**: Active in production, will improve data quality for multi-word keywords

**ðŸŽ¯ Daily Metrics Performance Optimization - DEPLOYED** (Earlier):
- âœ… **8x Performance Improvement**: Optimized `youtube_daily_metrics_unified_vm.py` with range queries
- âœ… **Issue Fixed**: Category aggregations only showing single keywords (e.g., only `qwen3` in ai_coding_agents)
- âœ… **Root Cause**: Individual Firebase document queries (90+ queries per category) causing slowness and incomplete data
- âœ… **Solution**: Replaced with efficient range queries using Firebase `where` clauses for date ranges
- âœ… **Before**: ~5+ minutes runtime with 1,270+ individual queries
- âœ… **After**: ~37 seconds runtime with efficient batch queries per category
- âœ… **Impact**: All keywords now properly appear in category time window aggregations (30_days, 90_days)
- âœ… **Deployed**: Optimized script deployed to VM at `/opt/youtube_app/src/analytics/metrics/`
- âœ… **Verified**: Script tested and working on production VM, ready for next 2:00 AM run
- âœ… **Keywords Fixed**: ai_coding_agents now shows all 7 keywords (claude code, codex, cursor, github copilot, qwen3, testsprite 20, windsurf)
- âœ… **All Categories**: Fix applies to all categories system-wide, not just coding agents

**ðŸŽ¯ Staggered Cron Schedule Implemented**:
- âœ… Replaced simultaneous instance starts with staggered cron entries
- âœ… Instance 1: Runs at :00, :10, :20, :30, :40, :50
- âœ… Instance 2: Runs at :03, :13, :23, :33, :43, :53 (3-minute offset)
- âœ… Instance 3: Runs at :06, :16, :26, :36, :46, :56 (6-minute offset)
- âœ… Interval metrics: Runs at :09, :19, :29, :39, :49, :59 (after all complete)
- âœ… Reduces server load by spreading instances across 6 minutes
- âœ… Each instance gets dedicated time without resource competition

**ðŸŽ¯ Log Cleanup System Added**:
- âœ… Created automated cleanup for collection logs older than 5 days
- âœ… Interactive script: `cleanup_old_collection_logs.py` for manual cleanup
- âœ… Automated script: `cleanup_old_logs_auto.py` for cron jobs
- âœ… Weekly cleanup cron: Sundays at 3 AM UTC
- âœ… Maintains database performance by removing old logs
- âœ… Logs cleanup statistics to `youtube_maintenance_logs` collection

**ðŸŽ¯ Interval Metrics Logging Fix**:
- âœ… Fixed interval metrics creating hash IDs in collection logs
- âœ… Updated to use Firebase client's `log_collection_run` method
- âœ… Ensures consistent timestamp-based document IDs
- âœ… Cleaned up 24 hash documents from interval metrics

### ðŸ”§ **Previous Updates (2025-08-05 Evening)**:

**ðŸŽ¯ Multi-Instance Collection System - WORKING**:
- âœ… Implemented 3-instance parallel collection to handle keyword scaling
- âœ… Created docker-compose-multi.yml with 3 VPN containers (ports 8000, 8003, 8004)
- âœ… Dynamic keyword distribution across instances (currently 5-5-6 split for 16 keywords)
- âœ… Created youtube_collection_manager_simple.py for simpler VPN handling
- âœ… Process locking prevents overlapping runs of same instance
- âœ… Fixed Firebase logging format with proper keywords_processed array and videos_per_keyword map
- âœ… Added update_keyword_timestamp method to FirebaseClient
- âœ… **CRITICAL FIX**: Added instance-specific Redis key namespacing to prevent duplicate detection between parallel instances
- âœ… System now collecting proper video counts (ChatGPT: 20 videos vs previous 5)
- âœ… Ready to scale to 40+ keywords without collection overlaps

**ðŸŽ¯ Collection Issue Resolution**:
- **Initial Problem**: Keywords increased causing collections to take >10 minutes
- **Root Cause 1**: Multiple instances overlapping and fighting over single VPN container
- **Root Cause 2**: Shared Redis cache causing false duplicates between parallel instances
- **Solution**: 3 parallel instances with dedicated VPN containers + instance-specific Redis namespacing
- **Result**: Each instance collects proper video counts, system ready for large-scale keyword growth

### ðŸ”§ **Earlier Updates (2025-08-05)**:

**ðŸŽ¯ Collection Logs Hash ID Fix**:
- âœ… Identified root cause: collection_logger.py was using session_id as document ID
- âœ… Fixed all Firebase client implementations to validate timestamp-based IDs
- âœ… Updated collection_logger.py to generate proper timestamp IDs (collection_YYYY-MM-DD_HH-MM-SS_UTC)
- âœ… Added ID validation to prevent future hash ID creation
- âœ… Created monitoring tools to detect and clean up hash IDs
- âœ… All collection logs now use consistent readable timestamp format

**ðŸŽ¯ Critical Fixes - Video Storage & Keywords**:
- âœ… Fixed video storage issue - Firestore requires parent documents for subcollections
- âœ… Created missing parent documents for all 16 keywords
- âœ… Updated scraper to auto-create parent documents before saving videos
- âœ… Synchronized all keywords across collections using reddit_keywords as baseline
- âœ… Merged duplicate video collections (stable_diffusion, leonardo_ai, runway)
- âœ… Fixed collection schedule to run every 10 minutes with interval metrics
- âœ… Cleaned up 95+ hash document IDs in youtube_collection_logs

**ðŸŽ¯ YouTube Filter Fix**:
- âœ… Fixed YouTube filter from `sp=EgQIARAB` to `sp=CAISBAgBEAE%253D`
- âœ… Now properly sorts by upload date within last hour
- âœ… Dramatically improves relevance of collected videos

### ðŸ”§ **Previous Updates (2025-08-05)**:

**ðŸŽ¯ Project Renaming** (Latest - 2025-08-05):
- âœ… Renamed from `wget_youtube_scraper` back to `youtube_app`
- âœ… Confirmed wget method captures 20 videos per keyword
- âœ… Updated all references and paths throughout the codebase
- âœ… Moved all Python scripts from root to src/ directories
- âœ… Updated all deployment scripts for new paths
- âœ… Cleaned up root directory - only config files remain
- âœ… Organized Python scripts in src/ directories

### ðŸ”§ **Previous Updates (2025-08-04)**:

**ðŸŽ¯ Platform Baseline System Simplified** (Latest):
- âœ… Removed complex platform baseline calculation script
- âœ… Implemented hardcoded platform baseline approach for simplicity
- âœ… Created set_platform_baseline.py for manual baseline management
- âœ… Set YouTube platform baseline to 150.0 videos/day (hardcoded)
- âœ… Updated all documentation to reflect hardcoded approach
- âœ… Verified velocity calculations working correctly with hardcoded baseline
- âœ… System deployed and operational on production VM

**ðŸŽ¯ Firebase Schema v2.0 Migration**:
- âœ… Successfully migrated Firebase schema to v2.0 standardized metrics
- âœ… Converted daily_metrics from subcollection to map field for all 15 keywords
- âœ… Updated 566 category snapshot documents with new field names
- âœ… Transformed field names: videos_found_in_day â†’ new_videos_in_day, views_count â†’ total_views
- âœ… Added standardized v2.0 fields: velocity (platform-normalized %), acceleration (keyword-relative ratio)
- âœ… Removed legacy metrics and cleaned up keyword document structure
- âœ… Updated youtube_daily_metrics_unified_vm.py to write new schema format
- âœ… Added current_velocity field updates to keywords for real-time tracking
- âœ… All production systems now using v2.0 schema with backward compatibility removed

**ðŸŽ¯ Standardized Metrics v2.0 Implementation**:
- âœ… Implemented platform-normalized velocity scoring system
- âœ… Added keyword-relative acceleration calculations
- âœ… Created momentum score (0-100) based on trend analysis
- âœ… Built unified trend score v2 combining velocity + momentum
- âœ… Enhanced youtube_daily_metrics_unified_vm.py with new scoring
- âœ… Updated category snapshots with standardized metrics
- âœ… Created platform baseline calculator for YouTube
- âœ… Added platform_metrics collection for baseline storage
- âœ… Updated firestore_mapping.md with v2.0 schema
- âœ… Comprehensive testing validated all calculations
- âœ… Cross-platform comparison now possible with normalized scores

**Key Benefits of New Metrics System**:
- ðŸ”¥ **Platform-Normalized Velocity**: 150% = 150% of YouTube platform average
- ðŸš€ **Keyword-Relative Acceleration**: 1.5x = 150% vs keyword's own baseline
- ðŸ“ˆ **Momentum Score**: 0-100 trend momentum using linear regression
- ðŸŽ¯ **Unified Trend Score**: Combined ranking score (60% velocity + 40% momentum)
- ðŸŒ **Cross-Platform**: Standardized scoring enables comparison across platforms

**Scheduled Function Paths Fixed**:
- âœ… Fixed cron_scraper_with_metrics.sh to use correct script paths
- âœ… Updated from module import to direct script execution
- âœ… All scheduled functions now pointing to reorganized project structure
- âœ… Verified scripts are executable and working

**Interval Metrics Timing Fixed**:
- âœ… Fixed interval metrics running every 5 minutes instead of hourly
- âœ… Disabled systemd analytics timer that was causing excessive runs
- âœ… Integrated interval metrics into hourly scraper cron job
- âœ… Now runs correctly: Scraper at :15, then interval metrics immediately after
- âœ… Proper data flow: Videos collected â†’ Interval metrics calculated â†’ Daily metrics aggregated

**Analytics Pipeline Fixed**:
- âœ… Fixed systemd service configuration for analytics
- âœ… Daily metrics cron job verified (runs at 2:00 AM daily)
- âœ… Interval metrics now calculating properly after each scraper run
- âœ… Created fix scripts for future troubleshooting
- âœ… All metrics services operational

**Video Collection Confirmed Working**:
- âœ… Videos ARE being collected successfully (56 videos in last run)
- âœ… Strict title filter disabled to improve collection rates
- âœ… Data properly stored in `youtube_videos/{keyword}/videos/`
- âœ… Interval metrics stored in `youtube_keywords/{keyword}/interval_metrics/`

### ðŸ”§ **Previous Updates (2025-01-03)**:

**Title Filtering Enhancement** (Latest):
- âœ… Added YOUTUBE_STRICT_TITLE_FILTER feature
- âœ… Only collects videos containing the search keyword in their title
- âœ… Defaults to true for improved data quality
- âœ… Environment variable: `YOUTUBE_STRICT_TITLE_FILTER=true`
- âœ… Reduces irrelevant data collection significantly

**Simplified Deployment Process**:
- âœ… 3-phase deployment process implemented
- âœ… No Git operations on production VM
- âœ… Artifact-based deployment for cleaner production
- âœ… Automated health checks and verification
- âœ… Zero-downtime deployments

**Deployment Complete** (13:00 UTC):
- Successfully deployed to VM via GitHub push
- Fixed all hardcoded paths from `/opt/youtube_scraper` to `/opt/youtube_app`
- Python virtual environment configured
- All dependencies installed
- Credentials properly configured

**Hourly Automation** (13:27 UTC):
- Cron job configured to run hourly at :15 past the hour
- Logs available at `/opt/youtube_app/logs/cron.log`
- Script: `/opt/youtube_app/cron_scraper.sh`

**Auto-Deployment Working**:
- GitHub Actions workflow active
- Push to main branch = automatic deployment
- Smart deployment detects changed files
- Automatic backup before updates
- Path fixes deployed and verified

**Current Issues Resolved**:
- âœ… Path migration completed
- âœ… Environment variables corrected (SURFSHARK_PRIVATE_KEY, SURFSHARK_ADDRESS)
- âœ… Firebase credentials deployed
- âœ… Logs directory created
- âœ… Hourly automation via cron job
- âœ… Title filtering implemented for better data quality

## Key Features

### ðŸŽ¯ **Deployment Process**
1. **Push to GitHub** â†’ Triggers auto-deployment
2. **Smart Detection** â†’ Only updates changed components
3. **Auto-Configure** â†’ New services detected and configured
4. **Backup First** â†’ Automatic backup before changes
5. **Auto-Rollback** â†’ If deployment fails

### ðŸ“ **Project Structure**
```
youtube_app/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ youtube_collection_manager.py  # Main orchestrator
â”‚   â”‚   â”œâ”€â”€ youtube_scraper_production.py  # Core scraping logic
â”‚   â”‚   â””â”€â”€ collectors/
â”‚   â”‚       â””â”€â”€ run_analytics.py           # Analytics runner
â”‚   â”œâ”€â”€ utils/                             # Utilities
â”‚   â”‚   â”œâ”€â”€ env_loader.py                  # Fixed for youtube_app paths
â”‚   â”‚   â”œâ”€â”€ logging_config_enhanced.py     # Dynamic log paths
â”‚   â”‚   â””â”€â”€ firebase_client_enhanced.py
â”‚   â””â”€â”€ analytics/                         # Analytics pipeline
â”‚       â””â”€â”€ metrics/
â”‚           â”œâ”€â”€ youtube_keywords_interval_metrics.py
â”‚           â””â”€â”€ youtube_daily_metrics_unified_vm.py
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ smart_deploy.sh          # Smart deployment script
â”‚   â”‚   â”œâ”€â”€ service_detector.py      # Auto-detect services
â”‚   â”‚   â””â”€â”€ backup_manager.py        # Backup/rollback
â”‚   â””â”€â”€ test_deployment.py           # Deployment verification
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ auto-deploy.yml          # GitHub Actions
â””â”€â”€ .env                             # Credentials (gitignored)
```

### ðŸ”’ **Security**
- `.env` file gitignored
- Firebase credentials file gitignored  
- Credentials added manually on VM after deployment
- VPN for anonymity (VM-only)

## Usage Instructions

### ðŸš€ **Deploy to Production**
```bash
# 1. Push to GitHub (triggers deployment)
git push origin main

# 2. Monitor deployment
# Check GitHub Actions: https://github.com/canaanhowell/youtube-scraper-production/actions

# 3. SSH to VM and add credentials (first time only)
ssh -i /workspace/droplet1 root@134.199.201.56
cd /opt/youtube_app
vim .env  # Add production credentials
```

### âš™ï¸ **Configure Title Filtering**
```bash
# In .env file, set title filtering (defaults to true)
YOUTUBE_STRICT_TITLE_FILTER=true  # Only collect videos with keyword in title
YOUTUBE_STRICT_TITLE_FILTER=false # Collect all videos from search results
```

### ðŸ“Š **Monitor System**
```bash
# Check cron job status
crontab -l

# View collection logs for all instances
tail -f logs/collector_1.log logs/collector_2.log logs/collector_3.log

# View main scraper log
tail -f logs/scraper.log

# View multi-instance cron log
tail -f logs/cron_multi.log

# View analytics logs
tail -f logs/analytics.log

# View daily metrics logs
tail -f logs/daily_metrics.log

# Check VPN containers status
docker ps | grep youtube-vpn

# Check systemd timers
systemctl list-timers --all | grep youtube

# Check deployment log
tail -f /var/log/youtube_deploy.log

# Manual backup/rollback if needed
python3 deployment/scripts/backup_manager.py backup
python3 deployment/scripts/backup_manager.py rollback

# Run daily metrics manually if needed
bash deployment/scripts/run_daily_metrics_now.sh

# Test individual instance
cd /opt/youtube_app && source venv/bin/activate
python src/scripts/youtube_collection_manager_simple.py --instance 1
```

## Important Notes

### âš ï¸ **Cannot Test Locally**
- VPN/Docker required (only on VM)
- Local testing limited to Firebase connection
- Full testing requires VM environment

### âœ… **Verification Checklist - MUST CHECK BEFORE DECLARING SUCCESS**
When implementing any collection system changes, verify ALL of the following:

1. **Process Running**: Check that collection processes start without errors
   ```bash
   tail -f logs/collector_*.log
   # âœ“ Should see "Starting collection" messages
   ```

2. **VPN Connected**: Verify VPN containers are healthy
   ```bash
   docker ps | grep youtube-vpn
   # âœ“ Should show "healthy" status for all 3 containers
   ```

3. **Videos Actually Collected**: Check Firebase for actual video data
   ```bash
   # Check collection logs in Firebase
   # âœ“ total_videos_collected should be > 0 (target: 40+ videos per run)
   # âœ“ videos_per_keyword should show 15-20 for active keywords like ChatGPT, Claude
   ```

4. **No wget Errors**: Verify wget is successfully fetching pages
   ```bash
   grep "Failed to fetch" logs/collector_*.log
   # âœ“ Should return no results or very few
   ```

5. **Firebase Verification**: Check actual video documents exist
   ```bash
   # In Firebase console: youtube_videos/{keyword}/videos/
   # âœ“ Should see new video documents with recent timestamps
   ```

6. **Redis Deduplication Working**: Verify instances aren't interfering
   ```bash
   # Each instance should show proper video counts, not excessive duplicates
   # âœ“ Instance logs should show reasonable duplicate ratios (not 90%+ duplicates)
   ```

**âš ï¸ NEVER declare success without verifying actual data collection AND proper video counts!**

### ðŸ“ **Required Environment Variables**
The `.env` file on VM must include:
```env
# Firebase
GOOGLE_SERVICE_KEY_PATH=/opt/youtube_app/ai-tracker-466821-892ecf5150a3.json
FIRESTORE_PROJECT_ID=ai-tracker-466821

# Redis
UPSTASH_REDIS_REST_URL=https://your-redis.upstash.io
UPSTASH_REDIS_REST_TOKEN=your-token

# VPN WireGuard Configuration
SURFSHARK_PRIVATE_KEY=your-wireguard-private-key
SURFSHARK_ADDRESS=10.14.0.2/16

# Environment
ENVIRONMENT=production
LOG_LEVEL=INFO

# YouTube Settings
YOUTUBE_STRICT_TITLE_FILTER=true  # Only collect videos with keyword in title (default: true)
```

## System Architecture

### **Production Components**:
- **YouTube Scraper**: wget-based scraper with VPN rotation
- **VPN Manager**: WireGuard integration with 24 US Surfshark servers
- **Data Storage**: Firebase Firestore for keywords and results
- **Cache Layer**: Upstash Redis REST API
- **Analytics Pipeline**: Daily metrics and trend analysis
- **Deployment**: GitHub Actions with smart detection

### **Key Commands**:
```bash
# Run collection manually
cd /opt/youtube_app && source venv/bin/activate
python src/scripts/youtube_collection_manager.py

# Check logs
tail -f /opt/youtube_app/logs/scraper.log

# Check cron logs
tail -f /opt/youtube_app/logs/cron.log

# Test with limited keywords
python src/scripts/youtube_collection_manager.py --test

# View next scheduled run
systemctl list-timers --all | grep youtube

# Set platform baseline (manual management)
python src/analytics/metrics/set_platform_baseline.py --baseline 150.0

# View current platform baseline
python -c "from src.utils.firebase_client import FirebaseClient; fb = FirebaseClient(); doc = fb.db.collection('platform_metrics').document('youtube').get(); print(f'Current baseline: {doc.to_dict().get(\"daily_baseline\", \"NOT FOUND\")}' if doc.exists else 'No baseline found')"

# Test new standardized metrics
python test_new_metrics.py

# Monitor for hash document IDs in collection logs
python src/scripts/utilities/monitor_collection_logs.py

# Check and clean up hash IDs if found
python check_and_fix_collection_logs.py

# Clean up any remaining hash document IDs
python cleanup_hash_logs.py
```

## Summary

The wget YouTube scraper is now:
- âœ… Fully deployed to production VM
- âœ… Auto-deployment enabled and tested
- âœ… All paths updated to `/opt/youtube_app`
- âœ… Environment variables properly configured
- âœ… Ready for production data collection
- âœ… Running hourly via cron job at :15 past each hour
- âœ… Analytics pipeline operational (interval metrics run immediately after scraper)
- âœ… Daily metrics calculating at 2:00 AM daily with **standardized v2.0 metrics** and **8x performance optimization**
- âœ… Platform baseline calculator for velocity normalization
- âœ… Cross-platform comparable metrics system
- âœ… All systemd services configured and active

### Active Services:
- **Multi-Instance Collection**: Staggered schedule every 10 minutes (individual cron entries)
  - Instance 1: Runs at :00 (youtube-vpn-1 container)
  - Instance 2: Runs at :03 (youtube-vpn-2 container)  
  - Instance 3: Runs at :06 (youtube-vpn-3 container)
  - Dynamic keyword distribution across instances
- **Interval Metrics**: Runs at :09 (after all instances complete)
- **Daily Metrics v2.0**: 2:00 AM daily (cron) - `/opt/youtube_app/deployment/cron_daily_metrics.sh` - **OPTIMIZED: 8x faster with range queries**
- **Weekly Log Cleanup**: Sundays at 3 AM UTC - removes logs >5 days old
- **Platform Baseline**: Hardcoded at 150.0 videos/day (managed via `src/analytics/metrics/set_platform_baseline.py`)
- **Analytics Timer**: DISABLED (was causing metrics to run every 5 minutes)

Any push to GitHub main branch automatically deploys to production!

## Critical Fixes Applied (August 5, 2025)

### Video Storage Fix
- **Issue**: Videos were being counted but not stored in Firestore
- **Root Cause**: Firestore requires parent documents to exist before adding to subcollections
- **Solution**: Created all 16 missing parent documents and updated scraper to auto-create them
- **Impact**: All videos now properly save to database

### Keyword Synchronization
- **Issue**: Mismatched keywords across collections (quotes, different IDs, duplicates)
- **Solution**: Synchronized all collections using reddit_keywords as baseline
- **Merges Completed**:
  - `"chatgpt"` â†’ `chatgpt` (removed duplicate with quotes)
  - `leonardo ai` â†’ `leonardo_ai` (696 videos)
  - `stable diffusion` â†’ `stable_diffusion` (620 videos)
  - `Runway` â†’ `runway` (686 videos)
- **Result**: All 16 keywords now match exactly across reddit_keywords, youtube_keywords, and youtube_videos

### Collection Schedule Update
- **Changed**: From hourly to every 10 minutes
- **Fixed**: Interval metrics now properly runs after each scraper execution
- **Filter**: Updated to `sp=CAISBAgBEAE%253D` for proper "last hour + sort by upload date"

### Data Cleanup
- **Removed**: 95+ hash document IDs from youtube_collection_logs
- **Fixed**: All collection logs now use readable timestamp IDs
- **Updated**: Cron script to ensure both scraper and interval metrics run together

### All YouTube Aggregation Fix
- **Issue**: youtube_categories/all_youtube document wasn't being updated by daily metrics
- **Root Cause**: Daily metrics script only processed categories with keywords, not aggregate views
- **Solution**: Added _update_all_youtube_snapshot method to create platform-wide aggregation
- **Impact**: Now creates all_youtube snapshots combining all keywords across all categories

### Collection Logs Hash ID Fix
- **Issue**: Documents in youtube_collection_logs were being created with auto-generated hash IDs
- **Root Cause**: collection_logger.py was using session_id as document ID instead of timestamp format
- **Solution**: 
  - Updated collection_logger.py to generate timestamp-based IDs (collection_YYYY-MM-DD_HH-MM-SS_UTC)
  - Added validation to all Firebase client methods to ensure proper ID format
  - Created monitoring and cleanup tools to detect and remove hash IDs
- **Impact**: All collection logs now use consistent, readable timestamp-based document IDs